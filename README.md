# ArtiCons
Artificial Consciousness

关于人工意识的可能性，最明确的一个观点来自于戴维·查默斯（David Chalmers）。
2011年，他在文章[A Computational Foundation for the Study of Cognition](https://web.archive.org/web/20151223105456/http://j-cs.org/gnuboard/bbs/download.php?bo_table=__vol012i4&wr_id=1&no=0)中提出，对于构建一个有意识的心灵来说，恰当类型的计算就足够了。
在摘要中，他这样定义他的目标：计算机能够执行计算。计算可以把握其他系统的抽象因果结构。

查默斯的观点中最具争议的部分是，他认为精神特性是“结构不变的”。
而人工意识的反对者们认为，查默斯的证明依赖于，默认所有的精神属性和外部链接都可以经过因果结构的抽象过程。

### · <=>---<=> · <=>---<=> · <=>---<=> · <=>---<=> · <=>---<=> · <=>---<=>

我个人的出发点是这样的。
现有的AI都是由问题前馈到答案的，比如
- 从各种图片映射到汽车、房子、字母、数字这样的概念，或者
- 从视频、语音、一种文本映射为另一种文本，或者
- 从给定的环境、规则、目标映射到动作的执行规律、偏好等。

这里缺乏的是一种真正的反馈机制，比如，
- 算法不能意识到当前面对的数据是自己之前没处理过，不熟悉的，或者
- 对现在的数据处理的过程，跟以往处理的过程非常不同，出错的概率很大，或者
- 当前结果的分布处以一种病态，它虽然大概率是平常的A，但也有较小的概率是危险的B，从而需要特别对待等等。

本质上，AI是一种预测能力；AC是一种反省能力。

只有做到这些，机器才能意识到自己的处境，并做出更明智的决定，从而避免自动驾驶汽车撞人或者严重偏离车道这样恶性事件。
